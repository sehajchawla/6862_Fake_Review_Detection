{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "T5 base comparison_Yelp and Hotels.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "environment": {
      "name": "common-cpu.m65",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/base-cpu:m65"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkTLZ3I4_7c_"
      },
      "source": [
        "#Fine-tuning T5 from the Huggingface Library Simple Transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6BzedyNpwRD"
      },
      "source": [
        "To do:\n",
        "1. Update examples of interrogatory text\n",
        "\n",
        "2. It seems like fake reviews\n",
        " like to \"paint a picture\" of the surroundingn, as opposed to concentrating on the actual thing being reviewed.\n",
        " the types of details they publish are too specific, and are narrative, as opposed to analytical. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSVlYZjTsmhC"
      },
      "source": [
        "The primary internet resources for \n",
        "\n",
        "\n",
        "*   Fine Tuning: https://simpletransformers.ai/docs/usage/\n",
        "*   Batch Size: https://machinelearningmastery.com/how-to-control-the-speed-and-stability-of-training-neural-networks-with-gradient-descent-batch-size/\n",
        "\n",
        "\n",
        "*   General: https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html\n",
        "*   Use: https://paperswithcode.com/method/t5\n",
        "\n",
        "\n",
        "*   PyPi Example: https://pypi.org/project/simpletransformers/0.51.0/\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXiUiZSSyuo2"
      },
      "source": [
        "!pip install simpletransformers\n",
        "import pandas as pd\n",
        "from simpletransformers.t5 import T5Model\n",
        "from pprint import pprint\n",
        "import logging\n",
        "# Making sure the environment is set up correctly for anyone running this notebook\n",
        "import datetime\n",
        "import json\n",
        "import os\n",
        "import pprint\n",
        "import random\n",
        "import string\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "import datetime as datetime\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "import sklearn\n",
        "from google.colab import drive\n",
        "from tensorflow import keras\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToSWFSITLa1G"
      },
      "source": [
        "# Settings\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyUjFnlbYbP7"
      },
      "source": [
        "**Getting the Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blEWqoL6aHHP"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-8-gBw1zmEG"
      },
      "source": [
        "def download_and_load_dataset(force_download=True):\n",
        "  return pd.read_csv(\"/content/drive/My Drive/6862_FakeReviewDetection/data/raw/yelp_processedUTF8.csv\", encoding = 'UTF-8')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkaA9fOEYbP9"
      },
      "source": [
        "**Processing the data**\n",
        "\n",
        "Purpose:\n",
        "1. T5 trainer and evaluator take in panda dataframes with three columns: \n",
        "\n",
        "*   prefix: A string indicating the task to perform,\n",
        "*   input_text: The input text sequence,\n",
        "*   target_text: The target sequence.\n",
        "\n",
        "We process our data to be in this form. The prefix value specifies the task we want the T5 model to perform. In our case, we use the prefix binary classification, since our objective is to classify a review as either real (0) or fake (1).\n",
        "\n",
        "Output:\n",
        "1.   Yelp reviews dataset for training, and generating metrics for the trained model\n",
        "2.    Hotels OPSPAM reviews dataset for evaluating the generalizability of the trained model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_57IQljLqems"
      },
      "source": [
        "#############################################################################\n",
        "################################ Yelp dataset################################\n",
        "#############################################################################\n",
        "reviews = download_and_load_dataset()\n",
        "reviews = reviews[['reviewText', 'fakeLabel']]\n",
        "def refinereviewText(row):\n",
        "    return row['reviewText'].lower()\n",
        "\n",
        "def refinefakeLabel(row):\n",
        "    if row['fakeLabel'] == -1:\n",
        "        return 0\n",
        "    else:\n",
        "        return 1\n",
        "\n",
        "reviews = reviews.dropna()\n",
        "reviews['reviewText'] = reviews.apply(refinereviewText, axis=1)\n",
        "reviews['fakeLabel'] = reviews.apply(refinefakeLabel, axis=1)\n",
        "\n",
        "reals = df_zeros = reviews[reviews['fakeLabel'] == 0]\n",
        "fakes = df_ones = reviews[reviews['fakeLabel'] == 1]\n",
        "df_zeros = reviews[reviews['fakeLabel'] == 0].sample(80466) #make divisible by 32? not necessary. model takes into account imperfect divisibility\n",
        "df_ones = reviews[reviews['fakeLabel'] == 1].sample(80466) #.sample(80466)\n",
        "df_combined = df_zeros.append(df_ones)\n",
        "df_combined = df_combined.sample(frac=1).reset_index(drop=True)\n",
        "df_smaller = df_combined.sample(frac=0.1).reset_index(drop=True)\n",
        "df_smaller\n",
        "\n",
        "reviews = df_smaller.copy()\n",
        "reviews = reviews.rename(columns={\"reviewText\": \"review\", \"fakeLabel\": \"deceptive\"})\n",
        "reviews.deceptive = reviews.deceptive.astype(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zsa0Zo8tYbP-"
      },
      "source": [
        "# Describe reviews\n",
        "reviews.describe()\n",
        "\n",
        "# Setting for pd\n",
        "#pd.set_option('display.max_colwidth', 10)\n",
        "\n",
        "#shape\n",
        "print(reviews.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GHYlsd2ROUU"
      },
      "source": [
        "# Shuffle and split the data\n",
        "cross_num = 4\n",
        "splitter = StratifiedShuffleSplit(n_splits=5, random_state=910, test_size=0.2)\n",
        "labels = [str(x) for x in reviews['deceptive']] #must change to string for T5, since it is a text-to-text model\n",
        "train_indices, test_indices = [x for x in splitter.split(reviews['review'], labels)][cross_num]\n",
        "\n",
        "training_X = np.array([reviews['review'][x] for x in train_indices])\n",
        "training_y = np.array([labels[x] for x in train_indices])\n",
        "test_X = np.array([reviews['review'][x] for x in test_indices])\n",
        "test_y = np.array([labels[x] for x in test_indices])\n",
        "\n",
        "# label_list is the list of labels, i.e. True, False or 0, 1 or 'dog', 'cat'\n",
        "label_list = ['0','1']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcaqrWmblDGX"
      },
      "source": [
        "#Creating training and testing dataset. Format to input into the T5 model which requires a dataframe with three columns: input_text, target_text, and prefix.\n",
        "yelp_train = pd.DataFrame(zip(training_X, training_y), columns=[\"input_text\", \"target_text\"])\n",
        "yelp_test = pd.DataFrame(zip(test_X, test_y), columns=[\"input_text\", \"target_text\"])\n",
        "\n",
        "yelp_train[\"prefix\"] = \"binary classification\"\n",
        "yelp_test[\"prefix\"] = \"binary classification\"\n",
        "\n",
        "yelp_test.describe()\n",
        "yelp_train.describe()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFsKe9UBoMQM"
      },
      "source": [
        "yelp_train.to_csv(\"/content/drive/My Drive/6862_FakeReviewDetection/data/raw/yelp_processedUTF8_train.csv\")\n",
        "yelp_train.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXEz2lbtbqf_"
      },
      "source": [
        "#############################################################################\n",
        "############################### Hotels dataset###############################\n",
        "#############################################################################\n",
        "import pandas as pd\n",
        "def download_and_load_dataset(force_download=True):\n",
        "  return pd.read_csv(\"/content/drive/My Drive/6862_FakeReviewDetection/data/raw/opinion_spam_corpusUTF8.csv\", encoding = 'UTF-8')\n",
        "hotel_test = download_and_load_dataset()\n",
        "hotel_test['reviewTest'] = hotel_test.apply(refinereviewText, axis=1)\n",
        "hotel_test = hotel_test[['reviewText', 'fakeLabel']].astype(str)\n",
        "hotel_test = hotel_test.rename(columns={\"reviewText\": \"input_text\", \"fakeLabel\": \"target_text\"})\n",
        "hotel_test[\"prefix\"] = \"binary classification\"\n",
        "\n",
        "hotel_test = hotel_test.sample(frac=1)\n",
        "print(hotel_test.target_text.head())\n",
        "# Create dataset to input into the trained T5 modell \n",
        "\n",
        "print(hotel_test.describe())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tj2z_SrLwHNf"
      },
      "source": [
        "hotel_prime = hotel_test.copy()\n",
        "hotel_prime['input_text'] = hotel_prime['input_text'] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYCJgjJwbtQO"
      },
      "source": [
        "**Train the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzjaNg4CYbQB"
      },
      "source": [
        "# Model arguments. Be careful to set arguments that allow the use of custom metrics.  \n",
        "# https://simpletransformers.ai/docs/t5-model/\n",
        "# We use convention-based defaults for the training batch size, and the number of epochs\n",
        "# Using a small # of epochs has a regularization effect (i.e. balances wanting to fit the training data well, and finding estimates\n",
        "# for parameters that generalize well \n",
        "\n",
        "model_args = {\n",
        "    \"reprocess_input_data\": True,\n",
        "    \"overwrite_output_dir\": True,\n",
        "    \"max_seq_length\": 10,\n",
        "    \"train_batch_size\": 32, #convention is 32; small batch sizes are noisy and offer a regularizing effect; the # of observations in the training dataset must be divisible by the train_batch_size\n",
        "    \"num_train_epochs\": 3,\n",
        "    \"save_eval_checkpoints\": True, \n",
        "    \"save_model_every_epoch\": True,\n",
        "    # \"silent\": True,\n",
        "    \"evaluate_generated_text\": True,\n",
        "    \"evaluate_during_training\": True, #[open] try setting to false for more epochs? for some reason, when i get to epoch 4 i get thrown an error -- dictionary given where numpy or tensor object expected\n",
        "    \"evaluate_during_training_verbose\": True, #try setting to false for more epochs?\n",
        "    #\"num_workers\": 1, doesn't fix memory problem...\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0MTPZ-FYbQD"
      },
      "source": [
        "# Custom metrics function\n",
        "\n",
        "def metrics_fn(l, p):\n",
        "\n",
        "    # Change into integer types \n",
        "    l_int = np.array(l).astype(int)\n",
        "    p_int = np.array(p).astype(int)\n",
        "\n",
        "    eval_accuracy=sklearn.metrics.accuracy_score(l, p)\n",
        "    f1_score =sklearn.metrics.f1_score(l, p, labels=['0', '1'], pos_label = '1')\n",
        "    auc = sklearn.metrics.roc_auc_score(l_int, p_int)\n",
        "    precision = sklearn.metrics.precision_score(l, p, pos_label = '1')\n",
        "    recall = sklearn.metrics.recall_score(l, p, labels=['0', '1'], pos_label = '1')\n",
        "    cm = sklearn.metrics.confusion_matrix(l, p, labels=['0', '1'])\n",
        "    return {'accuracy': eval_accuracy,\n",
        "            'f1_score': f1_score,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'auc': auc,\n",
        "            'confusion matrix': cm}\n",
        "    #return sum([1 if label == pred else 0 for label, pred in zip(labels, preds)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8xlO8ENeh4G"
      },
      "source": [
        "'''\n",
        "# Instantiate the model #Hard to get GPU on colab\n",
        "model = T5Model(\"t5\",\"t5-small\", args=model_args, use_cuda = True)\n",
        "# Train the model\n",
        "# Common errors returned:\n",
        "##                         mmap: cannnot allocate memory. In this case, \"Restart runtime\", and \"Run all\".\n",
        "model.train_model(yelp_train, output_dir = \"/content/drive/My Drive/6862_FakeReviewDetection/bestmodel\", eval_data=yelp_test, metrics = metrics_fn)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NHY_Y0kuxEA"
      },
      "source": [
        "**Evaluate on Yelp testing dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OgpNgYL4MRT"
      },
      "source": [
        "# Load model\n",
        "model = T5Model(\"t5\", \"/content/drive/My Drive/6862_FakeReviewDetection/bestmodel/checkpoint-1209-epoch-3\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyzCLdANrmBe"
      },
      "source": [
        "# Print out model metrics\n",
        "result_yelp_train = model.eval_model(yelp_train, metrics = metrics_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuFV2bVELxZ-"
      },
      "source": [
        "print(pd.DataFrame([result_yelp_train['metrics']]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOd614nIK7qR"
      },
      "source": [
        "# Print out model metrics\n",
        "result_yelp_test = model.eval_model(yelp_test, metrics = metrics_fn)\n",
        "print(pd.DataFrame([result_yelp_test['metrics']]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zWkHHxtcExX"
      },
      "source": [
        "**Evaluate generalizability to the hotels dataset**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuijwvDFcP2u"
      },
      "source": [
        "# Print out model metrics\n",
        "# Load a fine-tuned T5 model. Specify the name of the model (here, it is t5), and the directory of the trained model\n",
        "result_hotels= model.eval_model(hotel_test, metrics = metrics_fn)\n",
        "# Export\n",
        "pd.DataFrame([result_hotels['metrics']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlCGv0jbPbPm"
      },
      "source": [
        "# Numbers about exaggerations. \n",
        "# Change existing reviews to change the probability of making it fake. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaGSdMu9cVKU"
      },
      "source": [
        "**Understanding the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eV1MK_TPyimv"
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/My Drive/6862_FakeReviewDetection/data/raw/eval_dfUTF8.csv\", encoding = 'UTF-8').astype(str)\n",
        "\n",
        "preds = model.predict([\"binary classification: \" + description for description in df[\"input_text\"]])\n",
        "\n",
        "with open(\"/content/drive/My Drive/6862_FakeReviewDetection/data/raw/generated_classification.csv\", \"w\") as f:\n",
        "    for i, desc in enumerate(df[\"input_text\"].tolist()):\n",
        "        f.write(str(desc) + \"\\t\")\n",
        "        f.write(df['type'][i] + \"\\t\")\n",
        "        f.write(df['version'][i] + \"\\t\")\n",
        "        if preds[i]==\"1\":\n",
        "          f.write(\"Fake \\n\")\n",
        "        else:\n",
        "          f.write(\"Real \\n\")\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}